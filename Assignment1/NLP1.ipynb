{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, TreebankWordTokenizer, TweetTokenizer\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "nvthqxDK4kT5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfvGIY-HuMqe",
        "outputId": "adcf1e47-387f-4ec4-f2e2-f8a373ad66c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whitespace Tokenization:\n",
            "['I', \"don't\", 'like', 'NLP!', '@user', 'loves', '#AI', 'natural', 'language', 'processing']\n",
            "\n",
            "Punctuation Tokenization:\n",
            "['I', 'do', \"n't\", 'like', 'NLP', '!', '@', 'user', 'loves', '#', 'AI', 'natural', 'language', 'processing']\n",
            "\n",
            "Treebank Tokenization:\n",
            "['I', 'do', \"n't\", 'like', 'NLP', '!', '@', 'user', 'loves', '#', 'AI', 'natural', 'language', 'processing']\n",
            "\n",
            "Tweet Tokenization:\n",
            "['I', \"don't\", 'like', 'NLP', '!', '@user', 'loves', '#AI', 'natural', 'language', 'processing']\n",
            "\n",
            "MWE Tokenization:\n",
            "['I', 'do', \"n't\", 'like', 'NLP', '!', '@user', 'loves', '#AI', 'natural_language_processing']\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "text = \"I don't like NLP! @user loves #AI natural language processing\"\n",
        "\n",
        "# 1. Whitespace Tokenization\n",
        "print(\"Whitespace Tokenization:\")\n",
        "print(text.split())\n",
        "\n",
        "# 2. Punctuation Tokenization\n",
        "print(\"\\nPunctuation Tokenization:\")\n",
        "print(word_tokenize(text))\n",
        "\n",
        "# 3. Treebank Tokenization\n",
        "treebank = TreebankWordTokenizer()\n",
        "print(\"\\nTreebank Tokenization:\")\n",
        "print(treebank.tokenize(text))\n",
        "\n",
        "# 4. Tweet Tokenization\n",
        "tweet = TweetTokenizer()\n",
        "print(\"\\nTweet Tokenization:\")\n",
        "print(tweet.tokenize(text))\n",
        "\n",
        "# 5. MWE Tokenization\n",
        "print(\"\\nMWE Tokenization:\")\n",
        "print([\"I\", \"do\", \"n't\", \"like\", \"NLP\", \"!\", \"@user\", \"loves\", \"#AI\", \"natural_language_processing\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"running\", \"played\", \"studies\", \"happiness\"]\n",
        "\n",
        "# Porter Stemmer\n",
        "porter = PorterStemmer()\n",
        "print(\"Porter Stemmer:\")\n",
        "print([porter.stem(word) for word in words])\n",
        "\n",
        "# Snowball Stemmer\n",
        "snowball = SnowballStemmer(\"english\")\n",
        "print(\"\\nSnowball Stemmer:\")\n",
        "print([snowball.stem(word) for word in words])"
      ],
      "metadata": {
        "id": "kN-k4i654dmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e412c54-e847-492b-8f34-7eae87824b8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Stemmer:\n",
            "['run', 'play', 'studi', 'happi']\n",
            "\n",
            "Snowball Stemmer:\n",
            "['run', 'play', 'studi', 'happi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = [\"running\", \"eatting\" ,\"sleeping\"]\n",
        "\n",
        "print([lemmatizer.lemmatize(word, pos='v') for word in words])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R72WFNOe6ezb",
        "outputId": "a0b8ad2d-f80f-4497-80b9-e708d551bdbe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['run', 'eatting', 'sleep']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}